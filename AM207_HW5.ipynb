{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APMTH 207: Advanced Scientific Computing: \n",
    "## Stochastic Methods for Data Analysis, Inference and Optimization\n",
    "## Homework #5\n",
    "**Harvard University**<br>\n",
    "**Spring 2017**<br>\n",
    "**Instructors: Rahul Dave**<br>\n",
    "**Due Date: ** Thursday, March 2nd, 2017 at 11:59pm\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Upload your final answers as well as your iPython notebook containing all work to Canvas.\n",
    "\n",
    "- Structure your notebook and your work to maximize readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Problem 1: Monte Carlo and Simulation Revisited\n",
    "In Homework #2, we used simulation to compute the expected values of functions of random variables. That is, given a random variable $X$, defined over $\\mathbb{R}$, distributed according to the pdf $f_X$, and given a real-valued function of $X$, $h(X)$, we approximated $\\mathbb{E}[h(X)]$ as follows\n",
    "$$\n",
    "\\mathbb{E}[h(X)] = \\int_{\\mathbb{R}} h(x)f_X(x) dx \\approx \\frac{1}{N} \\sum_{i=1}^N h(X_i), \\quad X_i \\sim f_X\n",
    "$$\n",
    "\n",
    "Now, suppose that, instead of being given the distribution $f_X$ and $h(X)$, you were simply asked to evaluate the following complex integral:\n",
    "$$\n",
    "I=\\int_{0}^{\\infty} \\frac{x^4\\, \\sin\\left(\\sqrt{\\ln{(x+1)}}\\right)e^{-x}}{2+(x-4)^2} \\, dx \n",
    "$$\n",
    "A clever way to apply our Monte Carlo techniques would be to split the integrand as $h(x)f_X(x)$, and then approximate the integral as we have done in Homework #2:\n",
    "$$\n",
    "I = \\int_{0}^{\\infty} h(x)\\,f_X(x) dx  \\approx \\frac{1}{N} \\sum\\limits_{i=1}^{N} h(X_i)$$ \n",
    "where the $X_i$'s are independently drawn from $f_X(x)$. \n",
    "\n",
    "We denote the approximation of the integral as follows\n",
    "$$\\hat{I} = \\frac{1}{N} \\sum\\limits_{i=1}^{N} h(X_i), \\quad X_i \\sim f_X.$$\n",
    "\n",
    "\n",
    "### Part A:\n",
    "\n",
    "Rewrite your integrand as a product of two functions, $h(x)g(x)$, which can then be expressed as $h(x)f_X(x)$, where $f_X$ is a pdf (you may use one of the splits we propose in Part B or create your own). Explain why your choice of $h$ is appropriate. Explain why your choice of $g$ is appropriate for creating a pdf $f_X$.\n",
    "\n",
    "(**Hint:** think about what you would have to do do turn $g$ into a good pdf and $h$ into a function that can be evaluated at multiple samples from this pdf. Think about how to choose these two functions to make your Monte Carlo approximation of $I$ as accurate as possible.)\n",
    "\n",
    "\n",
    "### Part B:\n",
    "\n",
    "- Use $\\frac{1}{2+(x-4)^2}$ to create your pdf $f_X$. Implement a Metropolis algorithm to sample from $f_X$. Run the simulation 50 times for 150,000 points. Report the value of $\\hat{I}$ and that of Var[${\\hat{I}}$].\n",
    "\n",
    "\n",
    "- Use $xe^{-x}$ to create your pdf $f_X$. Implement a Metropolis algorithm to sample from $f_X$. Run the simulation 50 times for 150,000 points. Report the value of $\\hat{I}$ and that of Var[${\\hat{I}}$].\n",
    "\n",
    "\n",
    "- Compare the variance of your two estimates. Which choice of $f_X$ is better? Explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Metropolis Algorithm\n",
    "\n",
    "Suppose we ask you to memorize the order of the top five movies on IMDB. When we quiz you on the order afterwards, you might not recall the correct order, but the mistakes you will tend to make in your recall can be modeled by simple probabilistic models.\n",
    "  \n",
    "Let's say that the top five movies are:  \n",
    "1. *The Shawshank Redemption*\n",
    "2. *The Godfather*\n",
    "3. *The Godfather: Part II*\n",
    "4. *The Dark Knight*\n",
    "5. *Pulp Fiction*\n",
    "\n",
    "Let's represent this ordering by the vector $\\omega = (1,2,3,4,5)$. \n",
    "\n",
    "If you were to mistakenly recall the top five movies as:\n",
    "2. *The Godfather*\n",
    "3. *The Godfather: Part II*\n",
    "5. *Pulp Fiction*\n",
    "4. *The Dark Knight*\n",
    "1. *The Shawshank Redemption*\n",
    "\n",
    "We'd represent your answer by the vector $\\theta = (2,3,5,4,1)$.\n",
    "\n",
    "Now, we have a way of quantifying how wrong your answer can be. We define the Hamming distance between two top five rankings, $\\theta, \\omega$, as follows:\n",
    "$$d(\\theta, \\omega) = \\sum_{i=1}^5 \\mathbb{I}_{\\theta_i\\neq \\omega_i},$$ \n",
    "where $\\mathbb{I}_{\\theta_i\\neq \\omega_i}$ is the indicator function that returns 1 if $\\theta_i\\neq \\omega_i$, and 0 otherwise.\n",
    "\n",
    "For example, the Hamming distance between your answer and the correct answer is $d(\\theta, \\omega)=4$, because you only ranked *The Dark Knight* is correctly. \n",
    "\n",
    "Finally, let's suppose that the probability of giving a particular answer (expressed as $\\theta$) is modeled as\n",
    "$$ p(\\theta \\,|\\, \\omega, \\lambda) \\propto  e^{-\\lambda\\, d(\\theta,\\, \\omega)}.$$\n",
    "\n",
    "### Part A:\n",
    "\n",
    "Implement an Metropolis algorithm to produce sample guesses from 500 individuals, with various $\\lambda$ values, $\\lambda=0.2, 0.5, 1.0$. What are the top five possible guesses?\n",
    "\n",
    "### Part B:\n",
    "Compute the probability that *The Shawshank Redemption* is ranked as the top movie (ranked number 1) by the Metropolis algorithm sampler. Compare the resulting probabilities for the various different $\\lambda$ values. Summarize your findings."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
